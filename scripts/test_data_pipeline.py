#!/usr/bin/env python3
"""
Test script to demonstrate the comprehensive data processing pipeline.
"""

import sys
from pathlib import Path
import pandas as pd

# Add src to path
sys.path.append(str(Path(__file__).parent.parent / "src"))

from data.data_manager import DataManager
from data.data_pipeline import create_pipeline_config
from data.data_utils import describe_dataset, detect_outliers, feature_selection
from utils.logging_config import setup_logging, get_logger


def test_data_manager():
    """Test the enhanced DataManager."""
    print("ğŸ§ª Testing Enhanced DataManager")
    print("=" * 50)
    
    # Test with advanced pipeline
    print("\n1. Testing with Advanced Pipeline")
    manager = DataManager(use_pipeline=True, use_dvc=False)
    
    # Process data
    train_df, val_df, test_df = manager.process_data()
    
    print(f"âœ… Data processed successfully!")
    print(f"   Training: {train_df.shape}")
    print(f"   Validation: {val_df.shape}")
    print(f"   Test: {test_df.shape}")
    
    # Test feature names
    feature_names = manager.get_feature_names()
    print(f"   Features ({len(feature_names)}): {feature_names[:5]}...")
    
    # Test inference preparation
    sample_data = {
        'MedInc': 8.3252,
        'HouseAge': 41.0,
        'AveRooms': 6.984,
        'AveBedrms': 1.024,
        'Population': 322.0,
        'AveOccup': 2.555,
        'Latitude': 37.88,
        'Longitude': -122.23
    }
    
    # Add engineered features that the pipeline creates
    sample_data.update({
        'rooms_per_household': sample_data['AveRooms'] / sample_data['AveOccup'],
        'bedrooms_per_room': sample_data['AveBedrms'] / sample_data['AveRooms'],
        'population_per_household': sample_data['Population'] / sample_data['AveOccup'],
        'distance_to_sf': ((sample_data['Latitude'] - 37.7749)**2 + (sample_data['Longitude'] + 122.4194)**2)**0.5,
        'distance_to_la': ((sample_data['Latitude'] - 34.0522)**2 + (sample_data['Longitude'] + 118.2437)**2)**0.5,
        'coastal_proximity': 1 if sample_data['Longitude'] > -121.0 else 0,
        'income_low': 0, 'income_medium': 0, 'income_high': 1, 'income_very_high': 0,
        'age_new': 0, 'age_recent': 0, 'age_mature': 0, 'age_old': 1,
        'income_rooms_interaction': sample_data['MedInc'] * sample_data['AveRooms'],
        'income_age_interaction': sample_data['MedInc'] * sample_data['HouseAge']
    })
    
    try:
        inference_data = manager.prepare_inference_data(sample_data)
        print(f"âœ… Inference data prepared: {inference_data.shape}")
    except Exception as e:
        print(f"âŒ Inference preparation failed: {e}")
    
    # Get data summary
    summary = manager.get_data_summary()
    print(f"âœ… Data summary retrieved: {summary['datasets']['total_samples']:,} total samples")
    
    return train_df, val_df, test_df


def test_data_utils(train_df):
    """Test data utility functions."""
    print("\nğŸ§ª Testing Data Utilities")
    print("=" * 50)
    
    # Test dataset description
    print("\n1. Testing Dataset Description")
    description = describe_dataset(train_df)
    
    print(f"âœ… Dataset described:")
    print(f"   Shape: {description['basic_info']['shape']}")
    print(f"   Memory usage: {description['basic_info']['memory_usage_mb']:.2f} MB")
    print(f"   Missing values: {description['missing_values']['total_missing']}")
    print(f"   Duplicates: {description['duplicates']['total_duplicates']}")
    
    # Test outlier detection
    print("\n2. Testing Outlier Detection")
    numeric_cols = train_df.select_dtypes(include=['number']).columns[:3].tolist()
    outliers = detect_outliers(train_df, columns=numeric_cols, methods=['iqr', 'zscore'])
    
    print(f"âœ… Outliers detected:")
    for method, results in outliers.items():
        total_outliers = sum(info['count'] for info in results.values())
        print(f"   {method}: {total_outliers} outliers across {len(results)} columns")
    
    # Test feature selection
    print("\n3. Testing Feature Selection")
    target_col = 'MedHouseVal'
    if target_col in train_df.columns:
        feature_cols = [col for col in train_df.columns if col != target_col]
        X = train_df[feature_cols]
        y = train_df[target_col]
        
        try:
            fs_result = feature_selection(X, y, method='f_regression', k=5)
            print(f"âœ… Feature selection completed:")
            print(f"   Selected {len(fs_result['selected_features'])} features:")
            for feature, score in fs_result['ranked_features'][:5]:
                print(f"     {feature}: {score:.4f}")
        except Exception as e:
            print(f"âŒ Feature selection failed: {e}")


def test_pipeline_config():
    """Test pipeline configuration."""
    print("\nğŸ§ª Testing Pipeline Configuration")
    print("=" * 50)
    
    # Test default configuration
    print("\n1. Testing Default Configuration")
    config = create_pipeline_config()
    print(f"âœ… Default config created:")
    print(f"   Test size: {config.test_size}")
    print(f"   Validation size: {config.validation_size}")
    print(f"   Scaler type: {config.scaler_type}")
    print(f"   Feature engineering: {config.enable_feature_engineering}")
    print(f"   Outlier detection: {config.enable_outlier_detection}")
    
    # Test custom configuration
    print("\n2. Testing Custom Configuration")
    custom_config = create_pipeline_config(
        test_size=0.15,
        scaler_type="robust",
        enable_feature_engineering=True,
        outlier_threshold=2.5
    )
    print(f"âœ… Custom config created:")
    print(f"   Test size: {custom_config.test_size}")
    print(f"   Scaler type: {custom_config.scaler_type}")
    print(f"   Outlier threshold: {custom_config.outlier_threshold}")


def test_legacy_compatibility():
    """Test backward compatibility with legacy system."""
    print("\nğŸ§ª Testing Legacy Compatibility")
    print("=" * 50)
    
    # Test with legacy pipeline disabled
    print("\n1. Testing Legacy Mode")
    legacy_manager = DataManager(use_pipeline=False, use_dvc=False)
    
    try:
        train_df, test_df = legacy_manager.preprocess_data(legacy_manager.load_data())
        print(f"âœ… Legacy preprocessing completed:")
        print(f"   Training: {train_df.shape}")
        print(f"   Test: {test_df.shape}")
        
        # Test scaler loading
        scaler = legacy_manager.load_scaler()
        print(f"âœ… Legacy scaler loaded: {type(scaler).__name__}")
        
    except Exception as e:
        print(f"âŒ Legacy mode failed: {e}")


def main():
    """Main test function."""
    # Setup logging
    setup_logging(log_level="INFO")
    logger = get_logger(__name__)
    
    logger.info("ğŸš€ Starting comprehensive data pipeline tests...")
    
    try:
        # Test 1: Enhanced DataManager
        train_df, val_df, test_df = test_data_manager()
        
        # Test 2: Data utilities
        test_data_utils(train_df)
        
        # Test 3: Pipeline configuration
        test_pipeline_config()
        
        # Test 4: Legacy compatibility
        test_legacy_compatibility()
        
        print("\n" + "=" * 70)
        print("ğŸ‰ ALL TESTS COMPLETED SUCCESSFULLY! ğŸ‰")
        print("=" * 70)
        print("\nğŸ“Š Data Pipeline Summary:")
        print(f"   âœ… Advanced pipeline with feature engineering")
        print(f"   âœ… Data quality validation and profiling")
        print(f"   âœ… Outlier detection and handling")
        print(f"   âœ… Multiple scaling options")
        print(f"   âœ… Comprehensive data utilities")
        print(f"   âœ… Legacy compatibility maintained")
        print(f"   âœ… Train/Validation/Test splits: {train_df.shape[0]}/{val_df.shape[0]}/{test_df.shape[0]}")
        
        logger.info("âœ… All data pipeline tests passed successfully!")
        return 0
        
    except Exception as e:
        print(f"\nâŒ Tests failed: {e}")
        logger.error(f"Tests failed: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        return 1


if __name__ == "__main__":
    exit(main()) 